<!DOCTYPE html><html lang="en-US" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>第三章 | daluzi</title><meta name="description" content="一、深度学习推荐模型的演化关系图  整体来说，主要是以多层感知机(Multi-Layer Perceptron，MLP)为核心，通过改变神经网络的结构来构建各异的模型，比如：  改变神经网络的复杂程度 改变特征交叉方式 组合多种模型 FM模型的深度学习演化版本 注意力机制与推荐模型的结合 序列模型与推荐模型的结合 强化学习与推荐模型的结合 等  二、AutoRec——单隐层神经网络推荐模型 201"><meta name="keywords" content="recommendation,DL"><meta name="author" content="daluzi"><meta name="copyright" content="daluzi"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="../../../../img/bitbug_favicon.ico"><link rel="canonical" href="http://daluzi.top/2020/08/16/%E7%AC%AC%E4%B8%89%E7%AB%A0/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="第三章"><meta property="og:url" content="http://daluzi.top/2020/08/16/%E7%AC%AC%E4%B8%89%E7%AB%A0/"><meta property="og:site_name" content="daluzi"><meta property="og:description" content="一、深度学习推荐模型的演化关系图  整体来说，主要是以多层感知机(Multi-Layer Perceptron，MLP)为核心，通过改变神经网络的结构来构建各异的模型，比如：  改变神经网络的复杂程度 改变特征交叉方式 组合多种模型 FM模型的深度学习演化版本 注意力机制与推荐模型的结合 序列模型与推荐模型的结合 强化学习与推荐模型的结合 等  二、AutoRec——单隐层神经网络推荐模型 201"><meta property="og:image" content="https://i.loli.net/2020/08/16/iLayq4OwS6A5lNE.jpg"><meta property="article:published_time" content="2020-08-16T15:13:59.000Z"><meta property="article:modified_time" content="2020-08-25T09:45:24.291Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="../../../../css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="next" title="Docker" href="http://daluzi.top/2020/06/28/Docker/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="../img/bitbug_favicon.ico" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="../archives/"><div class="headline">Articles</div><div class="length_num">17</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="../tags/"><div class="headline">Tags</div><div class="length_num">26</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/"><div class="headline">Categories</div><div class="length_num">8</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="../index.html"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="../archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="../tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="../categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="../music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="../movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="../link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="../about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#null"><span class="toc-number">1.</span> <span class="toc-text">一、深度学习推荐模型的演化关系图</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#null"><span class="toc-number">2.</span> <span class="toc-text">二、AutoRec——单隐层神经网络推荐模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#null"><span class="toc-number">3.</span> <span class="toc-text">三、Deep Crossing模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#null"><span class="toc-number">4.</span> <span class="toc-text">四、NeuralCF模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#null"><span class="toc-number">5.</span> <span class="toc-text">五、PNN模型</span></a></li></ol></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://i.loli.net/2020/08/16/iLayq4OwS6A5lNE.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="../index.html">daluzi</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="../index.html"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="../archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="../tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="../categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="../music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="../movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="../link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="../about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">第三章</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="Created 2020-08-16 23:13:59"><i class="far fa-calendar-alt fa-fw"></i> Created 2020-08-16</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="Updated 2020-08-25 17:45:24"><i class="fas fa-history fa-fw"></i> Updated 2020-08-25</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="../../../../categories/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E3%80%8B/">《深度学习推荐系统》</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta__icon"></i><span>Post View:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1>一、深度学习推荐模型的演化关系图</h1>
<img src= "img/loading.gif" data-src="https://i.loli.net/2020/08/17/wEVPFOIKdDo1Rj6.jpg" alt="BBA75C44-476D-4786-B990-7EEE2FB4DF45.png" style="zoom:50%;" />
<p>整体来说，主要是以<font color='red'>多层感知机(Multi-Layer Perceptron，MLP)</font>为核心，通过改变神经网络的结构来构建各异的模型，比如：</p>
<ul>
<li>改变神经网络的复杂程度</li>
<li>改变特征交叉方式</li>
<li>组合多种模型</li>
<li>FM模型的深度学习演化版本</li>
<li>注意力机制与推荐模型的结合</li>
<li>序列模型与推荐模型的结合</li>
<li>强化学习与推荐模型的结合</li>
<li>等</li>
</ul>
<h1>二、AutoRec——单隐层神经网络推荐模型</h1>
<p><em>2015 澳大利亚国立大学提出。</em></p>
<p>它将<font color='red'>自编码器（AutoEncoder）的思想和协同过滤</font>结合，提出了一种单隐层神经网络推荐模型。</p>
<p><b>原理：</b></p>
<p>​		利用协同过滤中的共现矩阵，完成物品向量或用户向量的自编码。再利用自编码的结果得到用户对物品的预估评分，进而进行推荐排序。</p>
<blockquote>
<p>自编码器：假设其数据向量为r，自编码器的作用是将向量r作为输入，通过自编码器后，得到的输出向量尽量接近其本身。</p>
<p>假设自编码器的重建函数为$ h(r;\theta) $，那么自编码器的目标函数为：</p>
<p>$$ min_\theta\sum_{r\in S}||r - h(r;\theta)||_2^2 $$</p>
<p>其中，S是所有数据向量的集合。</p>
<p>一般来说，重建函数的参数数量远小于输入向量的维度数量，因此自编码器相当于完成了<b>数据压缩和降维</b>的工作。</p>
</blockquote>
<p>AutoRec使用单隐层神经网络的结构来解决构建重建函数的问题。模型结构图如下：</p>
<img src= "img/loading.gif" data-src="https://i.loli.net/2020/08/23/wo71GfOnrbxZcI6.jpg" alt="84CCD42D-718C-4122-8F08-7A8DCD155589.png" style="zoom:50%;" />
<p>网络的输入层是物品的评分向量<code>r</code>，输出层是一个多分类层。图中蓝色的神经元代表模型的<code>k</code>维单隐层，其中<code>k&lt;&lt;m</code>。图中的<code>V</code>和<code>W</code>分别代表输入层到隐层，以及隐层到输出层的参数矩阵。该模型结构代表的重建函数的具体形式如：</p>
<p>$$h(r;\theta)=f(W·g(V_r+\mu)+b)$$</p>
<p>其中，<code>f(.)</code>，<code>g(.)</code>分别为输出层神经元和隐层神经元的激活函数。</p>
<p><b>为防止过拟合，在加入<code>L2</code>正则化后，</b>AutoRec目标函数的具体形式为：</p>
<p>$$ min_\theta\sum_{i=1}<sup>n||r</sup>{(i)} - h(r<sup>{(i)};\theta)||_2</sup>2+\lambda/2·(||W||_F<sup>2+||V||_F</sup>2) $$</p>
<p>模型的训练利用梯度反向传播即可完成。</p>
<h1>三、Deep Crossing模型</h1>
<p><em>2016年，微软提出Deep Crossing模型，一次深度学习架构在推荐系统中的完整应用。</em></p>
<p><b>应用场景</b>：微软搜索引擎Bing中的搜索广告推荐场景。</p>
<p><b>目标：</b>用户搜索关键词后，搜索引擎除了返回相关结果，还会返回与搜索词相关的广告，因此要尽可能地<font color='red'>增加搜索广告的点击率，准确地预测广告点击率。</font></p>
<p>该模型完整的解决了从<b>特征工程、稀疏向量稠密化、多层神经网络进行优化目标拟合</b>等一系列深度学习在推荐系统中的应用问题。</p>
<p>基于此，微软使用的特征分成了三类：</p>
<ul>
<li>可以被处理成one-hot或者multi-hot向量的<b>类别型特征</b>：用户搜索词（query）、广告关键词（keyword）、广告标题（title）、落地页（landing page）、匹配类型（match type）；</li>
<li><b>数值型特征</b>：点击率、预估点击率（click prediction）；</li>
<li><b>需要进一步处理的特征</b>：广告计划（campaign）、曝光样例（impression）、点击样例（click）等，由于这些是一个特征的组别，就要把这些具体的部分拆开来分别处理。</li>
</ul>
<p><b>解决的问题：</b></p>
<ul>
<li>离散类特征编码后过于稀疏，不利于直接输入神经网络进行训练，<font color='blue'>如何解决稀疏特征向量稠密化的问题</font>（Embedding层、Stacking层）；</li>
<li><font color='blue'>如何解决特征自动交叉组合的问题</font>（Multiple Residual Units层）</li>
<li><font color='blue'>如何在输出层中达成问题设定的优化目标</font>（Scoring层）</li>
</ul>
<p><b>网络结构如下：</b></p>
<img src= "img/loading.gif" data-src="https://i.loli.net/2020/08/25/Y2rRUmLtgyBz3ih.jpg" alt="4EB1E155-2663-49C3-AD1E-A07C00A48211.png" style="zoom:50%;" />
<p>包括4层：Embedding层、stacking层、Multiple Residual Units层和Scoring层。各层作用如下：</p>
<ol>
<li>Embedding层：作用是将稀疏的类别型特征转换成稠密的Embedding向量，具体的策略包括Word2vec、Graph Embedding等；</li>
<li>Stacking层：作用是把不同的Embedding特征和数值型特征拼接在一起，形成新的包含全部特征的特征向量；</li>
<li>Multiple Residual Units层：作用是对特征向量各个维度进行充分的交叉组合。主要结构是多层感知机，该模型采用了<b>多层残差网络</b>作为MLP的具体实现。</li>
<li>Scoring层：作为输出层，作用是为了拟合优化目标存在的，对于CTR预估这类二分类问题，Scoring层往往使用逻辑回归模型；而对于图像分类等多分类问题，Scoring层往往采用softmax模型。</li>
</ol>
<blockquote>
<p><b>残差神经网络：</b></p>
<p>残差神经网络就是由残差单元组成的神经网络，具体结构如下：</p>
<img src= "img/loading.gif" data-src="https://i.loli.net/2020/08/25/fQyPaNArvOxdo9T.jpg" alt="E7D0AD35-937A-4A65-B49E-F8D6CCBF8D26.png" style="zoom:33%;" />
<p>特点：</p>
<ol>
<li>输入经过两层以ReLU为激活函数的全连接层后，生成输出向量；</li>
<li>输入可以通过一个短路通路直接与输出向量进行元素加操作，生成最终的输出向量</li>
</ol>
<p>在这样的结构下，残差单元中的两层ReLU网络其实拟合的是<font color='red'>输出和输入之间的残差</font>（$x<sup>0-x</sup>i$），这就是为什么要叫做残差神经网络。</p>
<p>残差神经网络的诞生主要是为了解决两个问题：</p>
<ul>
<li>神经网络是不是越深越好？对于传统的基于感知机的神经网络，当网络加深之后，往往存在过拟合现象，即网络越深，在测试集上的表现越差。而在残差网络中，由于有输入向量短路的存在，很多时候可以越过两层ReLU网络，减少过拟合现象的发生。</li>
<li>当神经网络足够深时，往往存在严重的梯度消失现象。（梯度消失现象是指在梯度反向传播过程中，越靠近输入端，梯度的幅度越小，参数收敛的速度越慢。）为了解决这个问题，残差单元使用了ReLU激活函数取代原来sigmoid激活函数。此外，输入向量短路相当于直接把梯度毫无变化地传递到下一层，这也使残差网络的收敛速度更快。</li>
</ul>
</blockquote>
<h1>四、NeuralCF模型</h1>
<p><em>2017年，新加坡国立大学提出基于深度学习的协同过滤模型NeuralCF。</em></p>
<p>下图为传统矩阵分解的网络化形式表示和NeuralCF模型的对比：</p>
<img src= "img/loading.gif" data-src="https://i.loli.net/2020/08/25/EF7geXozukZxjhY.jpg" alt="944F9428-2FAE-4623-A4D9-1D7F4255B2E3.png" style="zoom:50%;" />
<p>图的左半部分是传统MF的网络化形式表示，其中用户隐向量和物品隐向量都可以看作是Embedding层。可以看出，NeuralCF模型用“多层神经网络+输出层”的结构替代了矩阵分解模型中简单的内积操作。优点是：</p>
<ol>
<li>让用户向量和物品向量做更充分的交叉，得到更多有价值的特征组合信息；</li>
<li>引入更多的非线性特征让模型的表达能力更强。</li>
</ol>
<p><b>广义矩阵分解模型（Generalized Matrix Factorization）：</b>用任意的互操作形式代替用户和物品向量的互操作层。</p>
<p>基于此，该论文还提出了一种混合模型，整合了原始NeuralCF模型和以元素积为互操作的广义矩阵分解模型，如下：</p>
<img src= "img/loading.gif" data-src="https://i.loli.net/2020/08/25/Xw4WhbKeuCJMVLY.jpg" alt="45B2031A-5ADC-4C51-95D2-27D2A3C38AB0.png" style="zoom:50%;" />
<blockquote>
<p><b>softmax函数：</b></p>
<p>目前很多深度模型的输出层都使用softmax函数，<font color='red'>解决多分类问题的目标拟合问题。</font></p>
<p>数学形式：</p>
<p>$$\sigma(X)_i=\frac{exp(x_i)}{\sum<sup>n_{j=1}exp(x_i)},当i=1,…,n且X=[x_1,…,x_n]</sup>T\in\mathbb{R}$$</p>
<p>可以看出，softmax函数解决了从一个原始的n维向量，向一个n维的概率分布映射问题。</p>
<p>在分类问题上，softmax函数往往和交叉熵（cross-entropy）损失函数一起使用：</p>
<p>$$LOSS_{Cross Entropy}=-\sum_iy_iln(\sigma(x)_i)$$</p>
<p>其中$y_i$是第i个分类的真实标签值，$\sigma(x)_i$代表softmax函数对第i个分类的预测值。</p>
<p>因为softmax函数把分类输出标准化成了多个分类的概率分布，而交叉熵正好刻画了预测分类和真实结果之间的相似度，所以softmax函数往往与交叉熵搭配使用。</p>
<p>softmax函数的导数形式为：</p>
<p>$$ {\frac{\partial\sigma(x)_i}{\partial x_j}}=\begin{cases}<br>
\sigma(x)_i(1-\sigma(x)_j), &amp; i=j \<br>
-\sigma(x)_i·\sigma(x)_j &amp; i\neq j<br>
\end{cases}$$</p>
<p>基于链式法则，交叉熵函数到softmax函数第j维输入$x_j$的导数形式为：</p>
<p>$$\frac{\partial Loss}{\partial x_j}=\frac{\partial Loss}{\partial \sigma(x)}·\frac{\partial \sigma(x)}{\partial x_j}$$</p>
<p>在多分类问题中，真实值中只有一个维度是1，其余维度都为0，假设第k维是1，即$y_k=1$，那么交叉熵损失函数可以简化成如下形式：</p>
<p>$$LOSS_{Cross Entropy}=-\sum_iy_iln(\sigma(x)_i)=-y_k·ln(\sigma(x)_k)=-ln(\sigma(x)_k)$$</p>
<p>则有：</p>
<p>$$\frac{\partial Loss}{\partial x_j}=\frac{\partial(-ln(\sigma(x)_k))}{\partial\sigma(x)_k}·\frac{\partial\sigma(x)_k}{\partial x_j}=-\frac{1}{\sigma(x)_k}·\frac{\partial\sigma(x)_k}{\partial x_j}=\begin{cases}\sigma(x)_j-1, &amp; j=k \<br>
\sigma(x)_j, &amp; j\neq k<br>
\end{cases}$$</p>
<p>即$j=k$时，结果为算出的值减一，$j\neq k$时，为算出来的值。</p>
<p>可以看出，softmax函数与交叉熵的配合，不仅在数学含义上完美统一，而且在梯度形式上也非常简洁。基于上式的梯度形式，通过梯度反向传播的方法，即可完成整个神经网路权重的更新。</p>
</blockquote>
<h1>五、PNN模型</h1>
<p><em>2016年，上海交大提出PNN模型，给出了特征交互方式的几种设计思路。</em></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">daluzi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://daluzi.top/2020/08/16/%E7%AC%AC%E4%B8%89%E7%AB%A0/">http://daluzi.top/2020/08/16/%E7%AC%AC%E4%B8%89%E7%AB%A0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="../../../../tags/recommendation/">recommendation</a><a class="post-meta__tags" href="../../../../tags/DL/">DL</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/08/16/iLayq4OwS6A5lNE.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><button class="reward-button"><i class="fas fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="../../../../img/wepay.jpg" alt="wechat" onclick="window.open('../../../../img/wepay.jpg')"/><div class="post-qr-code__desc">wechat</div></li><li class="reward-item"><img class="post-qr-code__img" src="../../../../img/alipay.jpg" alt="alipay" onclick="window.open('../../../../img/alipay.jpg')"/><div class="post-qr-code__desc">alipay</div></li></ul></div></button></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="../../../06/28/Docker/"><img class="next-cover" data-src="https://i.loli.net/2020/06/28/hnm5d3vaqzFY9sJ.png" onerror="onerror=null;src='../../../../img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Docker</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/06/27/第二章/" title="第二章：推荐系统的进化之路"><img class="relatedPosts_cover" data-src="https://i.loli.net/2020/06/27/bALKwWlMsRvogtJ.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-27</div><div class="relatedPosts_title">第二章：推荐系统的进化之路</div></div></a></div><div class="relatedPosts_item"><a href="/2020/06/27/第一章/" title="第一章"><img class="relatedPosts_cover" data-src="https://i.loli.net/2020/06/27/TDHuM3RhKmGaqr6.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-27</div><div class="relatedPosts_title">第一章</div></div></a></div><div class="relatedPosts_item"><a href="/2020/05/23/The-FacT-Taming-Latent-Factor-Models-for-Explainability-with-Factorization-Trees/" title="The FacT: Taming Latent Factor Models for Explainability with Factorization Trees"><img class="relatedPosts_cover" data-src="https://i.loli.net/2020/05/23/T5g7xyimzRloCMt.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-23</div><div class="relatedPosts_title">The FacT: Taming Latent Factor Models for Explainability with Factorization Trees</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/17/图神经网络学习资源汇总/" title="Summary of learning resources"><img class="relatedPosts_cover" data-src="https://i.loli.net/2020/04/17/BgjAmd4Vb3ZHPUM.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-17</div><div class="relatedPosts_title">Summary of learning resources</div></div></a></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By daluzi</div><div class="framework-info"><span>Driven </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font_plus" title="Increase Font Size"><i class="fas fa-plus"></i></button><button id="font_minus" title="Decrease Font Size"><i class="fas fa-minus"></i></button><button class="translate_chn_to_cht" id="translateLink" title="Switch Between Traditional Chinese And Simplified Chinese">简</button><button id="darkmode" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="Setting"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="../../../../js/utils.js"></script><script src="../../../../js/main.js"></script><script src="../../../../js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script></body></html>