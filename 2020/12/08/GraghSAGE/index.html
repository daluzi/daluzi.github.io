<!DOCTYPE html><html lang="en-US" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>GraghSAGE | daluzi</title><meta name="description" content="GCN的缺点：   GCN的训练方式需要将邻接矩阵和特征矩阵一起放到内存或者显存里，在大规模图数据上是不可取的。 GCN在训练时需要知道整个图的结构信息（包括待预测的节点），这在现实某些任务中也不能实现（比如用今天训练的图模型预测明天的数据，那么明天的节点是拿不到的）。   Inductive learning v.s. Transductive learning  与其他类型的数据不同，图数"><meta name="keywords" content="Graph SAmple and aggreGatE"><meta name="author" content="daluzi"><meta name="copyright" content="daluzi"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="../../../../img/bitbug_favicon.ico"><link rel="canonical" href="http://daluzi.top/2020/12/08/GraghSAGE/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="GraghSAGE"><meta property="og:url" content="http://daluzi.top/2020/12/08/GraghSAGE/"><meta property="og:site_name" content="daluzi"><meta property="og:description" content="GCN的缺点：   GCN的训练方式需要将邻接矩阵和特征矩阵一起放到内存或者显存里，在大规模图数据上是不可取的。 GCN在训练时需要知道整个图的结构信息（包括待预测的节点），这在现实某些任务中也不能实现（比如用今天训练的图模型预测明天的数据，那么明天的节点是拿不到的）。   Inductive learning v.s. Transductive learning  与其他类型的数据不同，图数"><meta property="og:image" content="https://pic2.zhimg.com/80/v2-f8301d7397b1c703454e5adedbc9d621_1440w.jpg"><meta property="article:published_time" content="2020-12-08T07:37:52.000Z"><meta property="article:modified_time" content="2020-12-09T02:52:21.220Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="../../../../css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="prev" title="NMF" href="http://daluzi.top/2020/12/16/NMF/"><link rel="next" title="GCN" href="http://daluzi.top/2020/12/07/GCN/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="../img/bitbug_favicon.ico" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="../archives/"><div class="headline">Articles</div><div class="length_num">33</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="../tags/"><div class="headline">Tags</div><div class="length_num">42</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="../categories/"><div class="headline">Categories</div><div class="length_num">21</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="../index.html"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="../archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="../tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="../categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="../music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="../movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="../link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="../about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#null"><span class="toc-number">1.</span> <span class="toc-text">Inductive learning v.s. Transductive learning</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#null"><span class="toc-number">2.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#null"><span class="toc-number">3.</span> <span class="toc-text">算法细节</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-number">3.0.1.</span> <span class="toc-text">节点Embedding生成（即：前向传播）算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-number">3.0.2.</span> <span class="toc-text">采样（SAmple）算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-number">3.0.3.</span> <span class="toc-text">聚合器（Aggregator）算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-number">3.0.4.</span> <span class="toc-text">参数学习</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#null"><span class="toc-number">4.</span> <span class="toc-text">Code</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#null"><span class="toc-number">5.</span> <span class="toc-text">Reference</span></a></li></ol></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://pic2.zhimg.com/80/v2-f8301d7397b1c703454e5adedbc9d621_1440w.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="../index.html">daluzi</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="../index.html"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="../archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="../tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="../categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="../music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="../movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="../link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="../about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">GraghSAGE</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="Created 2020-12-08 15:37:52"><i class="far fa-calendar-alt fa-fw"></i> Created 2020-12-08</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="Updated 2020-12-09 10:52:21"><i class="fas fa-history fa-fw"></i> Updated 2020-12-09</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="../../../../categories/GNN/">GNN</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta__icon"></i><span>Post View:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p><img src= "img/loading.gif" data-src="https://i.loli.net/2020/12/09/sc3auIX6nzE5dAb.png" alt="framework"></p>
<blockquote>
<font color='red'>GCN的缺点：</font>

<ol>
<li>GCN的训练方式需要将邻接矩阵和特征矩阵一起放到内存或者显存里，在大规模图数据上是不可取的。</li>
<li>GCN在训练时需要知道整个图的结构信息（包括待预测的节点），这在现实某些任务中也不能实现（比如用今天训练的图模型预测明天的数据，那么明天的节点是拿不到的）。</li>
</ol>
</blockquote>
<h1>Inductive learning v.s. Transductive learning</h1>

<p>与其他类型的数据不同，图数据中的每一个节点可以通过边的关系利用其他节点的信息，这样就产生了一个问题：如果训练集上的节点通过边关联到了预测集或者验证集的节点，那么在训练的时候能否用它们的信息呢？</p>
<p>如果训练时用到了测试集或验证集样本的信息（或者说，测试集和验证集在训练的时候是可见的），我们把这种学习方式叫做Transductive learning，反之，称为inductive learning。</p>
<p>显然，我们所处理的大多数机器学习问题都是inductive learning，因为我们刻意的将样本集分为训练/验证/测试，并且训练的时候只用训练样本。然而，在GCN中，训练节点收集邻居信息的时候，用到了测试或者验证样本，所以它是Transductive的。</p>
<h1>概述</h1>

<p>GraphSAGE是一个inductive框架，在具体实现中，训练时它仅仅保留训练样本到训练样本的边。Inductive learning 的优点是可以利用已知节点的信息为未知节点生成Embedding。GraphSAGE 取自Graph SAmple and aggreGatE，SAmple指如何对邻居个数进行采样，aggreGatE指拿到邻居的embedding之后如何汇聚这些embedding以更新自己的embedding信息。</p>
<p><img src= "img/loading.gif" data-src="https://pic2.zhimg.com/80/v2-f8301d7397b1c703454e5adedbc9d621_1440w.jpg" alt="img"></p>
<p>上图为它的过程，分为三步：</p>
<ol>
<li>对邻居采样；</li>
<li>采样后的邻居embedding传到节点上来，并使用一个聚合函数聚合这些邻居信息以更新节点的embedding；</li>
<li>根据更新后的embedding预测节点的标签。</li>
</ol>
<h1>算法细节</h1>

<h3>节点Embedding生成（即：前向传播）算法</h3>

<p><em>这里讨论如何给图中的节点生成（或者说更新）embedding</em></p>
<p>假设我们已经完成了GraphSAGE的训练，因此模型的所有参数都已知了。具体来说，这些参数包括<code>K</code>个聚合器$AGGREGATE_k,\forall k\in 1,…,K$（见下图算法第4行）中的参数，这些聚合器被用来将邻居embedding信息聚合到节点上，以及一系列的权重矩阵$W^k,\forall k\in 1,…,K$(下图算法第3行)，这些权重矩阵被用作在模型层与层之间传播embedding的时候做非线性变换。</p>
<p><img src= "img/loading.gif" data-src="https://pic2.zhimg.com/80/v2-5ac927cd1fca0c700e18e3fc5ef55b45_1440w.jpg" alt="img"></p>
<p>算法的主要部分为：</p>
<ol>
<li>（line 1）初始化每个节点embedding为节点的特征向量；</li>
<li>（line 3）对于每个节点$v$；</li>
<li>（line 4）拿到它采样后的邻居的embedding$h_u,u\in \mathcal N(v)$并将其聚合，这里的$\mathcal N(v)$表示对邻居采样；</li>
<li>（line 5）根据聚合后的邻居embedding$(h_{N(v)})$和自身的embedding$(h_v)$通过一个非线性变换（$\sigma (W·\square)$）更新自身embedding。</li>
</ol>
<p>算法里的<code>K</code>：它既是聚合器的数量，也是权重矩阵的数量，还是网络的层数，这是因为每一次网络中聚合器和权重矩阵是共享的。</p>
<p>网络的层数可以理解为需要最大访问到的邻居的条数（hops），比如在上上张图（figure1）中，红色节点的更新拿到了它一、二跳邻居的信息，那么网络层数就是2。</p>
<p>为了更新红色节点，首先在第一层（k=1）我们会将蓝色节点的信息聚合到红色节点上，将绿色节点的信息聚合到蓝色节点上。在第二层（k=2）红色节点的embedding被再次更新，不过这次用的是更新后的蓝色节点embedding，这样就保证了红色节点更新后的embedding包括蓝色和绿色节点的信息。</p>
<h3>采样（SAmple）算法</h3>

<p>GraphSAGE采用了定长抽样的方法，具体来说，定义需要的邻居个数<code>S</code>，然后采用有放回的重采样/负采样方法达到<code>S</code>。保证每个节点（采样后的）邻居个数一致是为了把多个节点以及他们的邻居拼成一个Tensor送到GPU中进行批训练。</p>
<p><b>这里的重采样/负采样是指：若顶点邻居数少于<code>S</code>，则采用有放回的抽样，直到采样出<code>S</code>个顶点。若顶点邻居数大于<code>S</code>，则采用无放回的抽样。</b></p>
<h3>聚合器（Aggregator）算法</h3>

<p>GraphSAGE提供了多种聚合器（MEAN、pooling、LSTM），实验中效果最好的平均聚合器（mean aggregator），思想是：每个维度取对邻居embedding相应维度的均值，这个和GCN的做法基本一致（GCN实际上用的是求和）：</p>
<p><img src= "img/loading.gif" data-src="https://www.zhihu.com/equation?tex=h%5Ek_v%5Cleftarrow+%5Csigma%28%5Cbm%7BW%7D%5Ccdot+%5Ctext%7BMEAN%7D%28%5Cleft+%5C%7B+h_v%5E%7Bk-1%7D+%5Cright+%5C%7D+%5Ccup+%5Cleft%5C%7B+h_u%5E%7Bk-1%7D%2C%5Cforall+u%5Cin+N%28v%29+%5Cright%5C%7D%29" alt="[公式]"></p>
<h3>参数学习</h3>

<p>在定义好聚合函数之后，接下来就是对函数中的参数进行学习。文章分别介绍了无监督学习和监督学习两种方式。</p>
<ul>
<li>无监督学习形式</li>
</ul>
<p>基于图的损失函数希望临近的顶点具有相似的向量表示，同时让分离的顶点的表示尽可能区分。 目标函数如下</p>
<p><img src= "img/loading.gif" data-src="https://pic3.zhimg.com/80/v2-458b2b674141585314bd51fb04de309a_1440w.png" alt="img"></p>
<p>其中v是通过固定长度的随机游走出现在u附近的顶点， <img src= "img/loading.gif" data-src="https://www.zhihu.com/equation?tex=p_n" alt="[公式]"> 是负采样的概率分布， <img src= "img/loading.gif" data-src="https://www.zhihu.com/equation?tex=Q" alt="[公式]"> 是负样本的数量。</p>
<p>与DeepWalk不同的是，这里的顶点表示向量是通过聚合顶点的邻接点特征产生的，而不是简单的进行一个embedding lookup操作得到。</p>
<ul>
<li>监督学习形式</li>
</ul>
<p>监督学习形式根据任务的不同直接设置目标函数即可，如最常用的节点分类任务使用交叉熵损失函数。</p>
<hr>
<h1>Code</h1>

<p>这里以MEAN aggregator简单讲下聚合函数的实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">features, node, neighbours = inputs</span><br><span class="line"></span><br><span class="line">node_feat = tf.nn.embedding_lookup(features, node)</span><br><span class="line">neigh_feat = tf.nn.embedding_lookup(features, neighbours)</span><br><span class="line"></span><br><span class="line">concat_feat = tf.concat([neigh_feat, node_feat], axis=<span class="number">1</span>)</span><br><span class="line">concat_mean = tf.reduce_mean(concat_feat,axis=<span class="number">1</span>,keep_dims=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">output = tf.matmul(concat_mean, self.neigh_weights)</span><br><span class="line"><span class="keyword">if</span> self.use_bias:</span><br><span class="line">    output += self.bias</span><br><span class="line"><span class="keyword">if</span> self.activation:</span><br><span class="line">    output = self.activation(output)</span><br></pre></td></tr></table></figure>
<p>对于第 <img src= "img/loading.gif" data-src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 层的aggregator，<code>features</code>为第 <img src= "img/loading.gif" data-src="https://www.zhihu.com/equation?tex=k-1" alt="[公式]"> 层所有顶点的向量表示矩阵，<code>node</code>和<code>neighbours</code>分别为第k层采样得到的顶点集合及其对应的邻接点集合。</p>
<p>首先通过<code>embedding_lookup</code>操作获取得到顶点和邻接点的第 <img src= "img/loading.gif" data-src="https://www.zhihu.com/equation?tex=k-1" alt="[公式]"> 层的向量表示。然后通过<code>concat</code>将他们拼接成一个<code>(batch_size,1+neighbour_size,embeding_size)</code>的张量，使用<code>reduce_mean</code>对每个维度求均值得到一个<code>(batch_size,embedding_size)</code>的张量。</p>
<p>最后经过一次非线性变换得到<code>output</code>，即所有顶点的第 <img src= "img/loading.gif" data-src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 层的表示向量</p>
<ul>
<li>下面是完整的GraphSAGE方法的代码</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GraphSAGE</span><span class="params">(feature_dim, neighbor_num, n_hidden, n_classes, use_bias=True, activation=tf.nn.relu,</span></span></span><br><span class="line"><span class="function"><span class="params">              aggregator_type=<span class="string">'mean'</span>, dropout_rate=<span class="number">0.0</span>, l2_reg=<span class="number">0</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">    features = Input(shape=(feature_dim,))</span><br><span class="line">    node_input = Input(shape=(<span class="number">1</span>,), dtype=tf.int32)</span><br><span class="line">    neighbor_input = [Input(shape=(l,),dtype=tf.int32) <span class="keyword">for</span> l <span class="keyword">in</span> neighbor_num]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> aggregator_type == <span class="string">'mean'</span>:</span><br><span class="line">        aggregator = MeanAggregator</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        aggregator = PoolingAggregator</span><br><span class="line"></span><br><span class="line">    h = features</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(neighbor_num)):</span><br><span class="line">        <span class="keyword">if</span> i &gt; <span class="number">0</span>:</span><br><span class="line">            feature_dim = n_hidden</span><br><span class="line">        <span class="keyword">if</span> i == len(neighbor_num) - <span class="number">1</span>:</span><br><span class="line">            activation = tf.nn.softmax</span><br><span class="line">            n_hidden = n_classes</span><br><span class="line">        h = aggregator(units=n_hidden, input_dim=feature_dim, activation=activation, l2_reg=l2_reg, use_bias=use_bias,</span><br><span class="line">                       dropout_rate=dropout_rate, neigh_max=neighbor_num[i])(</span><br><span class="line">            [h, node_input,neighbor_input[i]])<span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    output = h</span><br><span class="line">    input_list = [features, node_input] + neighbor_input</span><br><span class="line">    model = Model(input_list, outputs=output)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>其中<code>feature_dim</code>表示顶点属性特征向量的维度，<code>neighbor_num</code>是一个<code>list</code>表示每一层抽样的邻居顶点的数量，<code>n_hidden</code>为聚合函数内部非线性变换时的参数矩阵的维度，<code>n_classes</code>表示预测的类别的数量，<code>aggregator_type</code>为使用的聚合函数的类别。</p>
<h1>Reference</h1>

<p><a href="https://zhuanlan.zhihu.com/p/79637787" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/79637787</a></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">daluzi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://daluzi.top/2020/12/08/GraghSAGE/">http://daluzi.top/2020/12/08/GraghSAGE/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="../../../../tags/Graph-SAmple-and-aggreGatE/">Graph SAmple and aggreGatE</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><button class="reward-button"><i class="fas fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="../../../../img/wepay.jpg" alt="wechat" onclick="window.open('../../../../img/wepay.jpg')"/><div class="post-qr-code__desc">wechat</div></li><li class="reward-item"><img class="post-qr-code__img" src="../../../../img/alipay.jpg" alt="alipay" onclick="window.open('../../../../img/alipay.jpg')"/><div class="post-qr-code__desc">alipay</div></li></ul></div></button></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="../../16/NMF/"><img class="prev-cover" data-src="https://baike.baidu.com/pic/%E9%9D%9E%E8%B4%9F%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/4571142/0/e850352ac65c10388b5c85e0b9119313b07e89f6?fr=lemma&amp;ct=single" onerror="onerror=null;src='../../../../img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">NMF</div></div></a></div><div class="next-post pull-right"><a href="../../07/GCN/"><img class="next-cover" data-src="http://tkipf.github.io/graph-convolutional-networks/images/gcn_web.png" onerror="onerror=null;src='../../../../img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">GCN</div></div></a></div></nav></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By daluzi</div><div class="framework-info"><span>Driven </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font_plus" title="Increase Font Size"><i class="fas fa-plus"></i></button><button id="font_minus" title="Decrease Font Size"><i class="fas fa-minus"></i></button><button class="translate_chn_to_cht" id="translateLink" title="Switch Between Traditional Chinese And Simplified Chinese">简</button><button id="darkmode" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="Setting"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="../../../../js/utils.js"></script><script src="../../../../js/main.js"></script><script src="../../../../js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script></body></html>